{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Party XGBoost on Data Subset\n",
    "First we'll train an XGBoost model on a subset of the data. Here, a party will only have a subset of the data that's globally available. Therefore, we would expect the trained model to not be as robust as a model trained on all available data. We'll look at the performance of a XGBoost model that's only trained on this subset. \n",
    "![title](img/exercise1.png)\n",
    "\n",
    "Note that this notebook is the same for aggregators and non-aggregators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in and examine the comma separated training data partition belonging to your party to get a better understanding of the data. \n",
    "* Training data for the insurance dataset is at `/data/insurance/insurance_training_{party_id}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Read in the comma separated training data using the pandas.read_csv() function \n",
    "# and print out the first few rows of the dataset using the .head() function\n",
    "\n",
    "training_data_path = # TODO\n",
    "\n",
    "training_data = pd.read_csv(training_data_path, sep=\",\", header=None)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into features and labels\n",
    "y_train = training_data.iloc[:, 0]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = training_data.iloc[:, 1:]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the test data.\n",
    "* Test data for the insurance dataset is located at `/data/insurance/insurance_test_{party_id}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the test data into features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "Train the model with the training data. Feel free to play with the hyperparameters. For example, you may want to adjust the `n_estimators` hyperparameter, which adjusts the number of trees in the ensemble. For a full list of hyperparameters, go here: https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The fit(features, labels) function will train the classifier\n",
    "arg1 = # TODO: set arg1 to the features\n",
    "arg2 = # TODO: set arg2 to the labels\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions and evaluate the model with the test data. Feel free to use different error functions. We suggest the sklearn `accuracy_score()` function for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the model to get predictions for the test set and calculate the prediction error\n",
    "preds = model.predict(x_test)\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your locally trained model's accuracy with those of other members of your federation. How do you think your locally trained model will perform on data that doesn't fit the distribution of your training data?\n",
    "\n",
    "Once you've finished discussing, let's move to [Exercise 2](./exercise2-member.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
