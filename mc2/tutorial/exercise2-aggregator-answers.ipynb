{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiparty XGBoost with Centralized Training\n",
    "In this exercise, we'll demonstrate a workflow in which each party has its own data and sends a copy of its data to the central server. Therefore, all the training data is sent over the network to the central server, who collects it and locally trains a model on all the data. The central server will then broadcast the trained model back to the parties, who will load the model and test it on their local test datasets. \n",
    "\n",
    "![title](img/exercise2.png)\n",
    "\n",
    "\n",
    "We will also measure the number of bytes sent over the network to show the large bandwidth needed for this workflow. \n",
    "This shows the benefits of using as much data as possible to make the model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transfer\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from Utils import scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we don't need to do this part, we think it's helpful to see how many bytes would be transferred over the network if you weren't the aggregator and had to send your training data over the network. Send the training data you used in Exercise 1 over the network to your `~/shared_data` directory. Note how many bytes are transferred.\n",
    "\n",
    "* Training data for the hospital dataset is at `/data/hospital/hospital_training_{party_id}.csv`\n",
    "* Training data for the insurance dataset is at `/data/insurance/insurance_training_{party_id}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you use the training data you used in exercise 1\n",
    "training_data = \"/path/to/training_data\" # TODO: fill in the path to the training data\n",
    "my_ip = \"aggregator_ip\" # TODO: fill in the IP of the aggregator\n",
    "dest_dir = \"~/shared_data\"\n",
    "scp(training_data, my_ip, dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the Received Data\n",
    "Wait for all parties to send your their data and load all the data that has been sent to your machine. For example, if three other parties sent you data, make 4 calls to `read_csv()`: one for your own data and three for the other parties' data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all the data in preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add training data to the argument passed to pd.concat()\n",
    "training_data_lst = [aggregator_training_data, p2_training_data, ]\n",
    "\n",
    "aggregated_training_data = pd.concat(training_data_lst) \n",
    "aggregated_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the aggregated training data into features and labels\n",
    "y_agg_train = aggregated_training_data.iloc[:, 0]\n",
    "x_agg_train = aggregated_training_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg1, arg2 = x_agg_train, y_agg_train # TODO: fill these variables in with the aggregated features and labels\n",
    "\n",
    "multiparty_model = xgb.XGBClassifier()\n",
    "multiparty_model.fit(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast the Trained Model\n",
    "Save the trained model and send it to all parties in the federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparty_model.save_model(\"ex2_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're the central server, run this cell as many times as needed to send the saved model\n",
    "# to all parties in the federation\n",
    "model_file = \"ex2_model.model\"\n",
    "dest_dir = \"~\"\n",
    "\n",
    "# TODO: fill in the IP addresses of all members of your federation\n",
    "dest_ips = []\n",
    "\n",
    "for ip in dest_ips:\n",
    "    scp(model_file, ip, dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load in your local test data and preprocess it to split it into features and labels\n",
    "test_data_subset = pd.read_csv('/data/hospital/hospital_test_1.csv', sep=\",\", header=None)\n",
    "y_test = test_data_subset.iloc[:, 0]\n",
    "x_test = test_data_subset.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg1, arg2 = x_test, y_test # TODO: set arg1 to the test features, arg2 to the test labels\n",
    "preds = multiparty_model.predict(arg1)\n",
    "print(accuracy_score(arg2, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results with other members of your federation. How did the centrally trained model perform on your local test data compared with the locally trained model? Did adding more data help?\n",
    "\n",
    "Once you're ready, please move to [Exercise 3](Exercise 3.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
