{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Party XGBoost on Data Subset\n",
    "First we'll train an XGBoost model on a subset of the data. This simulates the federated setting in that a party will only have a subset of the data that's available to the aggregator for training. We'll look at the performance of a XGBoost model that's only trained on this subset. \n",
    "![title](img/exercise1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in and examine the comma separated training data partition belonging to your party to get a better understanding of the data. \n",
    "\n",
    "Training data for the hospital dataset is at `/data/hospital/hospital_training_{party_id}.csv`. <br>\n",
    "Training data for the insurance dataset is at `/data/insurance/insurance_training_{party_id}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Read in the comma separated training data using the pandas.read_csv() function \n",
    "# and print out the first few rows of the dataset using the .head() function\n",
    "\n",
    "training_data_path = # TODO\n",
    "header = # TODO: set this to 0 if you're using the insurance dataset, None if you're using the hospital dataset\n",
    "\n",
    "training_data = pd.read_csv(training_data_path, sep=\",\", header=header)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into features and labels\n",
    "y_train = training_data.iloc[:, 0]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = training_data.iloc[:, 1:]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the test data.\n",
    "\n",
    "Test data for the hospital dataset is located at `/data/hospital/hospital_test_{party_id}.csv`<br>\n",
    "Test data for the insurance dataset is located at `/data/insurance/insurance_test_{party_id}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the test data into features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the training data. Feel free to play with the hyperparameters. For example, you may want to adjust the `n_estimators` hyperparameter, which adjusts the number of trees in the ensemble. For a full list of hyperparameters, go here: https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The fit(features, labels) function will train the classifier\n",
    "arg1 = # TODO: set arg1 to the features\n",
    "arg2 = # TODO: set arg2 to the labels\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions and evaluate the model with the test data. Feel free to use different error functions. We suggest the sklearn `accuracy_score()` function for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the model to get predictions for the test set and calculate the prediction error\n",
    "preds = model.predict(x_test)\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your locally trained model's accuracy with those of other members of your federation. How do you think your locally trained model will perform on data that doesn't fit the distribution of your training data?\n",
    "\n",
    "Once you've finished discussing, let's move to [Exercise 2](Exercise 2.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
