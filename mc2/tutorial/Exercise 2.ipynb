{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiparty XGBoost with Centralized Training\n",
    "In this exercise, we'll demonstrate a workflow in which each party has its own data and sends a copy of its data to the central server. Therefore, all the training data is sent over the network to the central server, who collects it and locally trains a model on all the data. The central server will then broadcast the trained model back to the parties, who will load the model and test it on their local test datasets. \n",
    "\n",
    "![title](img/exercise2.png)\n",
    "\n",
    "\n",
    "We will also measure the number of bytes sent over the network to show the large bandwidth needed for this workflow. \n",
    "This shows the benefits of using as much data as possible to make the model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that you've properly set up SSH credentials in Exercise 0. `scp` the training data you used in Exercise 1 to the central server. Note how many bytes are transferred over the network.\n",
    "\n",
    "As a reminder, the training data is located at `/data/<insurance or hospital>/<insurance or hospital>_training_<party ID>.csv`. For example, if you're party 2 and your federation is using the hospital dataset, your training data is at `/data/hospital/hospital_training_2.csv`.\n",
    "\n",
    "You can run this cell if you're the central server as well to see how much bandwidth sending the raw data over the network would take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you use the scp the training data you used in exercise 1\n",
    "\n",
    "!scp -v -P 5522 -o StrictHostKeyChecking=no /data/hospital/hospital_training_1.csv <central server ip>:~/shared_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're the central server, load all the data that has been sent to your machine. For example, if three other parties sent you data, make 4 calls to `read_csv()`: one for your own data and three for the other parties' data.\n",
    "\n",
    "**Do this only if you're the central server. If you're not the central server, time to take a break**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load in all the training data that the parties have sent\n",
    "# The data should've been sent to the ~/shared_data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all the data in preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_training_data = pd.concat([]) # TODO: add training data to the argument passed to pd.concat()\n",
    "aggregated_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the aggregated training data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fit a model to the aggregated training data\n",
    "multiparty_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model and send it to all parties in the federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparty_model.save_model(\"ex2_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're the central server, run this cell as many times as needed to send the saved model\n",
    "# to all parties in the federation\n",
    "!scp -v -P 5522 -o StrictHostKeyChecking=no ex2_model.model <party_ip>:~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not the central server, your break is over. The central server should have sent the centrally trained model to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're not the central server, ensure that you received the model and load it in\n",
    "multiparty_model = xgb.XGBClassifier()\n",
    "multiparty_model.load_model(\"ex2_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess your local test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load in your local test data and preprocess it to split it into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the model on your local test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results with other members of your federation. How did the centrally trained model perform on your local test data compared with the locally trained model? Did adding more data help?\n",
    "\n",
    "Once you're ready, please move to [Exercise 3](Exercise 3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
